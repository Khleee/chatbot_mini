{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from tokenization_kobert import KoBertTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent_list 생성\n",
    "\n",
    "with open('data/동원몰 챗봇_☆상용서버☆Live-dialog.json', 'r',encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "intent_list = []\n",
    "for x in json_data[\"intents\"]:\n",
    "    intent_list.append(x[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialogue 읽기\n",
    "\n",
    "with open('data/dialogue_test.json', 'r',encoding=\"utf-8\") as f2:\n",
    "    json_data2 = json.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1개 존재함\n",
      "사용할 GPU :  NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# gpu 메모리 청소\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# device = gpu 설정\n",
    "if torch.cuda.is_available():     \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('%d개 존재함' % torch.cuda.device_count())\n",
    "    print('사용할 GPU : ', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('GPU 없어서 CPU로 설정')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# 모델 load -> (나스 개인 폴더에 있으니 README.MD 참조해서 가져오셈\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(\"/model/kobert\").cuda()\n",
    "\n",
    "# 토크나이저 선언\n",
    "tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "\n",
    "# load 파라미터(변경시 꼭 수정해야해!)\n",
    "max_len = 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 돌려돌려\n",
    "def MRC(input_ids,attention_masks,start):\n",
    "    model2.eval()\n",
    "\n",
    "    predictions = []\n",
    "    last_layer_attentions = []\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_masks = attention_masks.to(device)\n",
    "\n",
    "    for i in range(len(input_ids)):\n",
    "        ids = input_ids[i].unsqueeze(0)\n",
    "        masks = attention_masks[i].unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model2(input_ids=ids,\n",
    "                            attention_mask=masks)\n",
    "\n",
    "        logits = outputs[0]\n",
    "        logits = torch.softmax(logits,dim=1)\n",
    "        last_layer_attention = outputs[1][-1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        last_layer_attention = last_layer_attention.detach().cpu().numpy()\n",
    "\n",
    "        last_layer_attentions.append(last_layer_attention) \n",
    "        predictions.append(logits)\n",
    "\n",
    "    probs = predictions[0][0]\n",
    "    pred_idx = np.argmax(probs)\n",
    "\n",
    "    return intent_list[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intents에 해당하는 다이얼로그 불러오고 상태 출력\n",
    "\n",
    "def DIA(start2):\n",
    "    if start2 == \"처음으로\":\n",
    "        time.sleep(0.5)\n",
    "        print(\"다시 돌아가겠습니다.\")\n",
    "        ending_temp = []\n",
    "        return ending_temp\n",
    "        \n",
    "    for x in json_data2: # \n",
    "        if x[\"title\"] == start2:\n",
    "            ending_temp = [x[\"output\"][\"text\"][\"values\"],x[\"next_step\"]]\n",
    "            \n",
    "            if x[\"type\"] == \"하나 선택\":\n",
    "                ending_temp.append(x[\"output\"][\"table\"])\n",
    "                return ending_temp\n",
    "            \n",
    "            return ending_temp\n",
    "            ## elif 의 무수한 type 경우수\n",
    "# 이것도 저것도 아니면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intents에 해당하는 슬롯 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\YU\\miniconda3\\envs\\py38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이해하기 어려워요. 쉽게 얘기해주세요\n",
      "이해하기 어려워요. 쉽게 얘기해주세요\n",
      "['사과', '바나나', '초코파이']\n",
      "확인했습니다. 해당 상품의 배송 조회 페이지로 이동하겠습니다. --페이지--\n",
      "이해하기 어려워요. 쉽게 얘기해주세요\n"
     ]
    }
   ],
   "source": [
    "### 시작 ###\n",
    "okay = 0\n",
    "text = \"안녕하세요 동원 챗봇 푸디입니다. 언제든 말씀해 주세요.\"\n",
    "while True:\n",
    "    # 처음\n",
    "    if okay == 0:\n",
    "        start = input(text)\n",
    "\n",
    "        # 종료시\n",
    "        if start == \"종료\":\n",
    "            break\n",
    "\n",
    "        # 토큰화 하기\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        ## 읽고 토큰화하기\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                                start,            \n",
    "                                add_special_tokens = True,\n",
    "                                max_length = max_len,\n",
    "                                pad_to_max_length = True, # padding =True 나 padding=\"longest\" 같은걸로 대체하세요\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt')\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        # mrc 돌리기\n",
    "        start2 = MRC(input_ids,attention_masks,start)\n",
    "        okay = 1 # 2번쨰 전환\n",
    "        ending = DIA(start2) # [문장,다음스텝,테이블]\n",
    "\n",
    "        if ending == None:\n",
    "            time.sleep(0.5)\n",
    "            print(\"이해하기 어려워요. 쉽게 얘기해주세요\")\n",
    "            okay = 0\n",
    "            continue\n",
    "        \n",
    "        # 테이블이 존재하면 출력해주기\n",
    "        if len(ending) == 3:\n",
    "            time.sleep(0.5)\n",
    "            print(str(ending[2]))\n",
    "        \n",
    "    # 2번째부터\n",
    "    if okay == 1:\n",
    "        if ending == None:\n",
    "            time.sleep(0.5)\n",
    "            print(\"이해하기 어려워요. 쉽게 얘기해주세요\")\n",
    "            okay = 0\n",
    "            continue\n",
    "        start = input(ending[0])\n",
    "\n",
    "        if start == \"종료\":\n",
    "            break\n",
    "\n",
    "        ## ending : values, next_step, (table)\n",
    "\n",
    "        ## 테이블이 있는 경우,\n",
    "        if len(ending) == 3:\n",
    "            if start in ending[2]: #테이블에 작성한 답이 있다면?\n",
    "                ending = DIA(ending[1][0]) # 정답\n",
    "                time.sleep(0.5)\n",
    "                print(str(ending[0][0])) # 랜덤없이 value 0번쨰 출력해줌\n",
    "            else: #테이블에 작성한 답이 없다면?\n",
    "                ending = DIA(ending[1][1]) # 오답\n",
    "                time.sleep(0.5)\n",
    "                print(str(ending[0][0])) # 랜덤없이 value 0번쨰 출력해줌\n",
    "                \n",
    "        ## 테이블이 없는 경우,\n",
    "        elif len(ending) == 2:\n",
    "            # next step이 없는경우\n",
    "            if len(ending[1]) == 0:\n",
    "                okay = 0\n",
    "            # next step이 3개 이상이면,(아직 미구현)\n",
    "            elif len(ending[1]) > 2:\n",
    "                ## 추후에 intents 정리되면 mrc2(긍정,부정, 1번, 2번..)로 처리 하면 되는 구역\n",
    "                if MRC(start) == \"긍정\":\n",
    "                    ending = DIA(ending[1][0])\n",
    "\n",
    "                elif MRC(start) == \"부정\":\n",
    "                    ending = DIA(ending[1][1])\n",
    "                else:\n",
    "                    ending = DIA(\"몰루\")\n",
    "        # 문장만 있는경우 = 미구현(지워도 무방)\n",
    "        elif len(ending) == 1:\n",
    "            ending = DIA(ending[1][0])\n",
    "\n",
    "        # 아예 없다 => 다시 처음으로 돌리기 위해 만듬\n",
    "        elif len(ending) == 0:\n",
    "            okay = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66793dee8b4a2983b6dd1bee8f592930418cb9cc68c57734dfcad44387fdcccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
